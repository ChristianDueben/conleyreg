% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/conleyreg.R
\name{conleyreg}
\alias{conleyreg}
\title{Conley standard error estimations}
\usage{
conleyreg(
  formula,
  data,
  dist_cutoff,
  model = c("ols", "logit", "probit"),
  unit = NULL,
  time = NULL,
  lat = NULL,
  lon = NULL,
  kernel = c("bartlett", "uniform"),
  lag_cutoff = 0,
  intercept = T,
  verbose = T,
  ncores = NULL,
  dist_comp = c("precise", "fast")
)
}
\arguments{
\item{formula}{regression equation as formula or character string}

\item{data}{input data, either in non-spatial data frame format (includes tibbles and data tables) with columns denoting coordinates or in sf format with a spatial
points geometry. When using a non-spatial data frame format, the coordinates must be longlat. sf objects can use any projection.}

\item{dist_cutoff}{the distance cutoff in km}

\item{model}{the applied model. Either \code{ols} (default), \code{logit}, or \code{probit}. \code{logit} and \code{probit} are currently restricted to
cross-sectional applications.}

\item{unit}{the variable identifying the cross-sectional dimension. Only needs to be specified, if data is not cross-sectional. Assumes that units do not change their
location over time.}

\item{time}{the variable identifying the time dimension}

\item{lat}{the variable specifying the latitude in longlat format}

\item{lon}{the variable specifying the longitude in longlat format}

\item{kernel}{the kernel applied within the radius. Either \code{bartlett} (default) or \code{uniform}}

\item{lag_cutoff}{the cutoff along the time dimension. Defaults to 0, meaning that standard errors are only adjusted cross-sectionally.}

\item{intercept}{boolean specifying whether to include an intercept. Defaults to \code{TRUE}. Fixed effects models omit the intercept automatically.}

\item{verbose}{boolean specifying whether to print messages on intermediate estimation steps. Defaults to \code{TRUE}.}

\item{ncores}{the number of CPU cores to use in the estimations. Defaults to the machine's number of CPUs. Does not affect cross-sectional applications.}

\item{dist_comp}{choice between \code{precise} (default) and \code{fast} distance computations when data is longlat. Even when choosing \code{precise}, you can still
tweak the performance by setting the library that the \code{sf} package uses in distance computations. \code{sf::sf_use_s2(T)} makes it rely on s2 which should be
faster than the alternative choice of GEOS with \code{sf::sf_use_s2(F)}. With \code{precise}, distances are great circle distances, with \code{fast} they are
haversine distances. Non-longlat data is not affected by this parameter and always uses Euclidean distances.}
}
\value{
Returns a \code{lmtest::coeftest} matrix of coefficient estimates and standard errors. It can be printed in Latex format using e.g. the \code{texreg} package.
}
\description{
This function estimates ols, logit, and probit models with Conley standard errors.
}
\details{
This code is an extension and modification of earlier Conley standard error implementations by (i) Richard Bluhm, (ii) Luis Calderon and Leander Heldring,
(iii) Darin Christensen and Thiemo Fetzer, and (iv) Timothy Conley.
}
\references{
\insertCite{*}{conleyreg}
\insertAllCited{}
}
